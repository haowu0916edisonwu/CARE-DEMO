{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0da1b44ed8ed407b92ec1834d6afdf85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_75aebf711a9d4c5dbbe4e3f9f19342fb"
          }
        },
        "6b3817bd7d9e49d8b3d5f711c532ea53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b74ee70ca9f4551842e69c2358afdbd",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1951c27c2e63463386b43e29efc82477",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "2aa2a862004943609319fb846db0f991": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_e8025ade42ad40e19c6682b76a765158",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4bf76f96caa94de88cd5ee278c31a7f6",
            "value": ""
          }
        },
        "27a327e61e324238a70da5bbf633c6a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_7541c932f4de4fddb8ab95ef4abf389d",
            "style": "IPY_MODEL_854d20635a0e4b30bd1d08ee5eb79007",
            "value": true
          }
        },
        "8d5d60791d3247ae94fb75280d25b7c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_ea9239f0b4524a04b84291f54d964aea",
            "style": "IPY_MODEL_1c9815a063484c979284a6fc6e5d8527",
            "tooltip": ""
          }
        },
        "99006ce12dd24ca0971262a5a729a1ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2938816f2a2f4cab9cf252860efebd93",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_74ed741dddd84eea81ebf8364d58fca5",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "75aebf711a9d4c5dbbe4e3f9f19342fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "1b74ee70ca9f4551842e69c2358afdbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1951c27c2e63463386b43e29efc82477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8025ade42ad40e19c6682b76a765158": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bf76f96caa94de88cd5ee278c31a7f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7541c932f4de4fddb8ab95ef4abf389d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "854d20635a0e4b30bd1d08ee5eb79007": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea9239f0b4524a04b84291f54d964aea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c9815a063484c979284a6fc6e5d8527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "2938816f2a2f4cab9cf252860efebd93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74ed741dddd84eea81ebf8364d58fca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf13bdb2171642f4a075f7b75a67cd40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c002add73e345b295b60214145a56fa",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0c8b8c51090d4d0787e4d64a5fb77798",
            "value": "Connecting..."
          }
        },
        "0c002add73e345b295b60214145a56fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c8b8c51090d4d0787e4d64a5fb77798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIaW_ydHk3qa",
        "outputId": "59a29154-2f8a-41cf-b9c6-f7942e6b737d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÂºÄÂßãÂàùÂßãÂåñ L4 ÁéØÂ¢É...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/CARE_L4_Full\n",
            "/content/drive/MyDrive/CARE_L4_Full/CARE\n",
            "\u001b[0m\u001b[01;34mconfig\u001b[0m/                evaluate_closedbook.sh  \u001b[01;34mft_results\u001b[0m/  requirements.txt\n",
            "data_preprocess.ipynb  evaluate.sh             pretrain.sh  \u001b[01;34msrc\u001b[0m/\n",
            "eun_temp.ipynb         finetune.sh             README.md\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "print(\"ÂºÄÂßãÂàùÂßãÂåñ L4 ÁéØÂ¢É...\")\n",
        "\n",
        "# 1. ÊåÇËΩΩ‰∫ëÁõò (Èò≤Ê≠¢Êñ≠ÂºÄËøûÊé•ÂêéÊï∞ÊçÆ‰∏¢Â§±)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. ÂàõÂª∫Âπ∂ËøõÂÖ•Â∑•‰ΩúÁõÆÂΩï\n",
        "project_root = '/content/drive/MyDrive/CARE_L4_Full'\n",
        "os.makedirs(project_root, exist_ok=True)\n",
        "%cd {project_root}\n",
        "\n",
        "# 3. ÂÖãÈöÜ‰ª£Á†Å\n",
        "if not os.path.exists(\"CARE\"):\n",
        "    !git clone https://github.com/eunseongc/CARE.git\n",
        "%cd CARE\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üõë Ê≠£Âú®ÊâßË°å„ÄêÂº∫Âà∂Ë∑≥ËøáÁºñËØë„ÄëÊñπÊ°à...\")\n",
        "\n",
        "# 1. ÂÖàÊääÊâÄÊúâÊñá‰ª∂ËøòÂéüÂà∞ÂàùÂßãÁä∂ÊÄÅ (Ê∏ÖÈô§‰πãÂâçÁöÑ‰øÆÊîπ)\n",
        "!git checkout .\n",
        "\n",
        "# 2. „ÄêÊ†∏ÂøÉÊìç‰Ωú„ÄëÁõ¥Êé•‰ªé requirements.txt ‰∏≠Âà†Êéâ flash-attn\n",
        "# ËøôÊ†∑ pip install Êó∂Â∞±‰ºöÂÆåÂÖ®Êó†ËßÜÂÆÉÔºåÁû¨Èó¥ÂÆåÊàêÔºÅ\n",
        "!sed -i '/flash-attn/d' requirements.txt\n",
        "\n",
        "print(\"üì¶ 3. ÂÆâË£Ö‰æùËµñ (ÊûÅÈÄüÁâà - Êó†ÈúÄÁºñËØë)...\")\n",
        "# ËøôÊ¨°ÂÆâË£Ö‰ºöÈ£ûÂø´ÔºåÂõ†‰∏∫Âè™Ë£ÖÊôÆÈÄöÂåÖ\n",
        "!pip install -r requirements.txt\n",
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfCXkQ_6l7iV",
        "outputId": "4d85cd0e-5558-40e8-d4c7-5ded6c06c8c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üõë Ê≠£Âú®ÊâßË°å„ÄêÂº∫Âà∂Ë∑≥ËøáÁºñËØë„ÄëÊñπÊ°à...\n",
            "Updated 23 paths from the index\n",
            "üì¶ 3. ÂÆâË£Ö‰æùËµñ (ÊûÅÈÄüÁâà - Êó†ÈúÄÁºñËØë)...\n",
            "Requirement already satisfied: transformers==4.51.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (4.51.0)\n",
            "Requirement already satisfied: accelerate==0.27.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.27.2)\n",
            "Requirement already satisfied: datasets==2.17.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.17.1)\n",
            "Requirement already satisfied: wandb==0.21.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (0.21.3)\n",
            "Requirement already satisfied: peft==0.14.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (0.14.0)\n",
            "Requirement already satisfied: tiktoken==0.9.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (0.9.0)\n",
            "Requirement already satisfied: protobuf==5.29.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (5.29.1)\n",
            "Requirement already satisfied: sentencepiece==0.2.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (1.26.4)\n",
            "Requirement already satisfied: rouge==1.0.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (1.0.1)\n",
            "Requirement already satisfied: huggingface_hub==0.34.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (0.34.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.0->-r requirements.txt (line 1)) (3.20.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.0->-r requirements.txt (line 1)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.0->-r requirements.txt (line 1)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.0->-r requirements.txt (line 1)) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.0->-r requirements.txt (line 1)) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.0->-r requirements.txt (line 1)) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.0->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.0->-r requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.27.2->-r requirements.txt (line 2)) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.27.2->-r requirements.txt (line 2)) (2.9.0+cu126)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.17.1->-r requirements.txt (line 3)) (18.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.12/dist-packages (from datasets==2.17.1->-r requirements.txt (line 3)) (0.7)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.17.1->-r requirements.txt (line 3)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==2.17.1->-r requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==2.17.1->-r requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==2.17.1->-r requirements.txt (line 3)) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.17.1->-r requirements.txt (line 3)) (2023.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==2.17.1->-r requirements.txt (line 3)) (3.13.2)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb==0.21.3->-r requirements.txt (line 4)) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb==0.21.3->-r requirements.txt (line 4)) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb==0.21.3->-r requirements.txt (line 4)) (4.5.1)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb==0.21.3->-r requirements.txt (line 4)) (2.12.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb==0.21.3->-r requirements.txt (line 4)) (2.47.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb==0.21.3->-r requirements.txt (line 4)) (4.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from rouge==1.0.1->-r requirements.txt (line 10)) (1.17.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub==0.34.4->-r requirements.txt (line 11)) (1.2.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.17.1->-r requirements.txt (line 3)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.17.1->-r requirements.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.17.1->-r requirements.txt (line 3)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.17.1->-r requirements.txt (line 3)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.17.1->-r requirements.txt (line 3)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.17.1->-r requirements.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.17.1->-r requirements.txt (line 3)) (1.22.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb==0.21.3->-r requirements.txt (line 4)) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb==0.21.3->-r requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb==0.21.3->-r requirements.txt (line 4)) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb==0.21.3->-r requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.51.0->-r requirements.txt (line 1)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.51.0->-r requirements.txt (line 1)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.51.0->-r requirements.txt (line 1)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.51.0->-r requirements.txt (line 1)) (2025.11.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 2)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 2)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 2)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 2)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 2)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 2)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 2)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 2)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 2)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 2)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 2)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 2)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 2)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 2)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.17.1->-r requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.17.1->-r requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.17.1->-r requirements.txt (line 3)) (2025.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb==0.21.3->-r requirements.txt (line 4)) (5.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 2)) (3.0.3)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.49.0)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2023.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "import os\n",
        "\n",
        "# 1. ÁôªÂΩï (Â¶ÇÊûú‰πãÂâçÊ≤°ÁôªÂΩïËøá)\n",
        "print(\"ËØ∑Âú®‰∏ãÊñπËæìÂÖ• Hugging Face Token:\")\n",
        "login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34,
          "referenced_widgets": [
            "0da1b44ed8ed407b92ec1834d6afdf85",
            "6b3817bd7d9e49d8b3d5f711c532ea53",
            "2aa2a862004943609319fb846db0f991",
            "27a327e61e324238a70da5bbf633c6a5",
            "8d5d60791d3247ae94fb75280d25b7c8",
            "99006ce12dd24ca0971262a5a729a1ab",
            "75aebf711a9d4c5dbbe4e3f9f19342fb",
            "1b74ee70ca9f4551842e69c2358afdbd",
            "1951c27c2e63463386b43e29efc82477",
            "e8025ade42ad40e19c6682b76a765158",
            "4bf76f96caa94de88cd5ee278c31a7f6",
            "7541c932f4de4fddb8ab95ef4abf389d",
            "854d20635a0e4b30bd1d08ee5eb79007",
            "ea9239f0b4524a04b84291f54d964aea",
            "1c9815a063484c979284a6fc6e5d8527",
            "2938816f2a2f4cab9cf252860efebd93",
            "74ed741dddd84eea81ebf8364d58fca5",
            "bf13bdb2171642f4a075f7b75a67cd40",
            "0c002add73e345b295b60214145a56fa",
            "0c8b8c51090d4d0787e4d64a5fb77798"
          ]
        },
        "id": "lPGFFC_wmKHS",
        "outputId": "b0956f36-be01-4828-fe5e-db49fc9268bf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ËØ∑Âú®‰∏ãÊñπËæìÂÖ• Hugging Face Token:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0da1b44ed8ed407b92ec1834d6afdf85"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"‰∏ãËΩΩÊ®°ÂûãÂíåÊï∞ÊçÆ...\")\n",
        "# ‰∏ãËΩΩÊùÉÈáç\n",
        "!huggingface-cli download eunseong/care_mistral_pt --local-dir checkpoints/care_mistral_pt\n",
        "# ‰∏ãËΩΩÊï∞ÊçÆ\n",
        "!huggingface-cli download eunseong/data_care --repo-type dataset --local-dir data_care --local-dir-use-symlinks False\n",
        "\n",
        "# ÂáÜÂ§á Demo Êñá‰ª∂\n",
        "!mkdir -p data_care/finetune\n",
        "!cp -f data_care/finetune/nq_mistral.jsonl data_care/finetune/nq_mistral.jsonl_demo\n",
        "!cp -f data_care/finetune/nq_valid.jsonl data_care/finetune/nq_valid.jsonl_demo\n",
        "\n",
        "print(\"Êï∞ÊçÆÂáÜÂ§áÂÆåÊØï\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxQVEDRu1d-I",
        "outputId": "63d3ffd3-90f8-410e-aa3b-9868133b0e60"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‰∏ãËΩΩÊ®°ÂûãÂíåÊï∞ÊçÆ...\n",
            "\u001b[33m‚ö†Ô∏è  Warning: 'huggingface-cli download' is deprecated. Use 'hf download' instead.\u001b[0m\n",
            "Fetching 4 files:   0% 0/4 [00:00<?, ?it/s]Downloading 'ckpt.pth' to 'checkpoints/care_mistral_pt/.cache/huggingface/download/I5mKl6660ZnMyBqW_iS6OPv3c_M=.0522ef56a7571452ebb09574c01eb85281b69d0d0ba4374503a7a9230c1b25d5.incomplete'\n",
            "Downloading 'config.json' to 'checkpoints/care_mistral_pt/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.3922dfe7ce26246a10351110000f99431696f233.incomplete'\n",
            "Downloading '.gitattributes' to 'checkpoints/care_mistral_pt/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.a6344aac8c09253b3b630fb776ae94478aa0275b.incomplete'\n",
            "Downloading 'README.md' to 'checkpoints/care_mistral_pt/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.7b95401dc46245ac339fc25059d4a56d90b4cde5.incomplete'\n",
            "\n",
            "ckpt.pth:   0% 0.00/1.01G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "config.json: 2.97kB [00:00, 4.42MB/s]\n",
            "Download complete. Moving file to checkpoints/care_mistral_pt/config.json\n",
            "\n",
            "\n",
            "README.md: 100% 31.0/31.0 [00:00<00:00, 174kB/s]\n",
            "Download complete. Moving file to checkpoints/care_mistral_pt/README.md\n",
            "\n",
            "\n",
            ".gitattributes: 1.52kB [00:00, 6.44MB/s]\n",
            "Download complete. Moving file to checkpoints/care_mistral_pt/.gitattributes\n",
            "Fetching 4 files:  25% 1/4 [00:00<00:02,  1.18it/s]\n",
            "ckpt.pth:   0% 1.06M/1.01G [00:03<55:03, 305kB/s]\u001b[A\n",
            "ckpt.pth:   7% 68.1M/1.01G [00:07<01:26, 10.9MB/s]\u001b[A\n",
            "ckpt.pth:  20% 202M/1.01G [00:07<00:20, 40.0MB/s] \u001b[A\n",
            "ckpt.pth:  33% 336M/1.01G [00:07<00:08, 77.7MB/s]\u001b[A\n",
            "ckpt.pth:  47% 470M/1.01G [00:07<00:04, 125MB/s] \u001b[A\n",
            "ckpt.pth:  60% 605M/1.01G [00:07<00:02, 183MB/s]\u001b[A\n",
            "ckpt.pth:  73% 739M/1.01G [00:08<00:01, 250MB/s]\u001b[A\n",
            "ckpt.pth:  87% 873M/1.01G [00:08<00:00, 321MB/s]\u001b[A\n",
            "ckpt.pth: 100% 1.01G/1.01G [00:08<00:00, 118MB/s]\n",
            "Download complete. Moving file to checkpoints/care_mistral_pt/ckpt.pth\n",
            "Fetching 4 files: 100% 4/4 [00:09<00:00,  2.29s/it]\n",
            "/content/drive/MyDrive/CARE_L4_Full/CARE/checkpoints/care_mistral_pt\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/commands/download.py:141: FutureWarning: Ignoring --local-dir-use-symlinks. Downloading to a local directory does not use symlinks anymore.\n",
            "  warnings.warn(\n",
            "\u001b[33m‚ö†Ô∏è  Warning: 'huggingface-cli download' is deprecated. Use 'hf download' instead.\u001b[0m\n",
            "Fetching 24 files:   0% 0/24 [00:00<?, ?it/s]Still waiting to acquire lock on data_care/.cache/huggingface/.gitignore.lock (elapsed: 0.1 seconds)\n",
            "Still waiting to acquire lock on data_care/.cache/huggingface/.gitignore.lock (elapsed: 0.1 seconds)\n",
            "Downloading 'eval/nq/retrieval/colbertv2/test.jsonl' to 'data_care/.cache/huggingface/download/eval/nq/retrieval/colbertv2/3cj0bj5eu12ak_liUN7b-S5ObFs=.f546b5fa5afbd6c4869cbaa25d55af09d39cfa40.incomplete'\n",
            "Downloading 'eval/factkg/retrieval/colbertv2/test_question_aware.jsonl' to 'data_care/.cache/huggingface/download/eval/factkg/retrieval/colbertv2/bZSJqojxeCw2Z-a73e3etb5DupM=.5ebb66710a0069e397ba8eae4f123d8f8e8e3ed2.incomplete'\n",
            "Downloading '.gitattributes' to 'data_care/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.399d0893236ebd885bddde5f6a21823931fcbcc3.incomplete'\n",
            "Downloading 'eval/nq/test.jsonl' to 'data_care/.cache/huggingface/download/eval/nq/3cj0bj5eu12ak_liUN7b-S5ObFs=.4bef7ab5dc3463b6aaef48f20ddbf3d45a29f29e.incomplete'\n",
            "Downloading 'eval/nq/retrieval/colbertv2/test_question_aware.jsonl' to 'data_care/.cache/huggingface/download/eval/nq/retrieval/colbertv2/bZSJqojxeCw2Z-a73e3etb5DupM=.c19a76200e59d0b55a3a0a72f15dab9cc21ceb14.incomplete'\n",
            "Downloading 'eval/factkg/test.jsonl' to 'data_care/.cache/huggingface/download/eval/factkg/3cj0bj5eu12ak_liUN7b-S5ObFs=.1cbb553ed3542d34ca39319665268871d9617037.incomplete'\n",
            "Downloading 'eval/factkg/retrieval/colbertv2/test.jsonl' to 'data_care/.cache/huggingface/download/eval/factkg/retrieval/colbertv2/3cj0bj5eu12ak_liUN7b-S5ObFs=.69db404a1f804f20748bf4cff1de30b962e81dd9.incomplete'\n",
            "Downloading 'eval/nq/train.jsonl' to 'data_care/.cache/huggingface/download/eval/nq/uLTL3nZkD53R_81J3siCIpm58Y8=.d4d78c953cb77fa27c86bc5c000fbe11a2aa60d4f05f292f510302e03fcc2c18.incomplete'\n",
            "\n",
            "test.jsonl: 0.00B [00:00, ?B/s]\u001b[A\n",
            "\n",
            "test.jsonl: 2.78MB [00:00, 123MB/s]\n",
            "Download complete. Moving file to data_care/eval/nq/retrieval/colbertv2/test.jsonl\n",
            "\n",
            ".gitattributes: 2.91kB [00:00, 3.59MB/s]\n",
            "Download complete. Moving file to data_care/.gitattributes\n",
            "\n",
            "test.jsonl: 0.00B [00:00, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "test.jsonl: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "test.jsonl: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "test.jsonl: 533kB [00:00, 11.0MB/s]\n",
            "Download complete. Moving file to data_care/eval/nq/test.jsonl\n",
            "test.jsonl: 1.32MB [00:00, 25.1MB/s]\n",
            "Download complete. Moving file to data_care/eval/factkg/test.jsonl\n",
            "\n",
            "\n",
            "test_question_aware.jsonl: 1.62MB [00:00, 15.4MB/s]\u001b[A\u001b[A\n",
            "test_question_aware.jsonl: 3.04MB [00:00, 35.9MB/s]\n",
            "Download complete. Moving file to data_care/eval/nq/retrieval/colbertv2/test_question_aware.jsonl\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "test.jsonl: 3.71MB [00:00, 35.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "test_question_aware.jsonl: 7.77MB [00:00, 30.8MB/s]\n",
            "Download complete. Moving file to data_care/eval/factkg/retrieval/colbertv2/test_question_aware.jsonl\n",
            "test.jsonl: 6.86MB [00:00, 30.5MB/s]\n",
            "Download complete. Moving file to data_care/eval/factkg/retrieval/colbertv2/test.jsonl\n",
            "Fetching 24 files:   8% 2/24 [00:01<00:11,  1.90it/s]Downloading 'eval/triviaqa/train.jsonl' to 'data_care/.cache/huggingface/download/eval/triviaqa/uLTL3nZkD53R_81J3siCIpm58Y8=.20299d01596763b7fca23d6666bb88017ff32030ab14c7f96d495d61ea3f988f.incomplete'\n",
            "Downloading 'eval/triviaqa/retrieval/colbertv2/test_question_aware.jsonl' to 'data_care/.cache/huggingface/download/eval/triviaqa/retrieval/colbertv2/bZSJqojxeCw2Z-a73e3etb5DupM=.7299e2a93c38f87c77272eae9133c0d9e9b2f696ad43c122b1cad390c6e922a7.incomplete'\n",
            "Downloading 'eval/triviaqa/test.jsonl' to 'data_care/.cache/huggingface/download/eval/triviaqa/3cj0bj5eu12ak_liUN7b-S5ObFs=.1d07072281f413e2257b67ca0dc69e5556a86e29.incomplete'\n",
            "Downloading 'eval/truthfulqa/retrieval/colbertv2/test.jsonl' to 'data_care/.cache/huggingface/download/eval/truthfulqa/retrieval/colbertv2/3cj0bj5eu12ak_liUN7b-S5ObFs=.ee003a190a48fb5430c330820f9463fa5333f30c.incomplete'\n",
            "Downloading 'eval/triviaqa/retrieval/colbertv2/test.jsonl' to 'data_care/.cache/huggingface/download/eval/triviaqa/retrieval/colbertv2/3cj0bj5eu12ak_liUN7b-S5ObFs=.957bacac14a70b7c50d3afe14b0e90751eebd947.incomplete'\n",
            "\n",
            "\n",
            "eval/triviaqa/train.jsonl:   0% 0.00/34.2M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "eval/triviaqa/retrieval/colbertv2/test_q(‚Ä¶):   0% 0.00/11.1M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[ADownloading 'eval/truthfulqa/retrieval/colbertv2/test_question_aware.jsonl' to 'data_care/.cache/huggingface/download/eval/truthfulqa/retrieval/colbertv2/bZSJqojxeCw2Z-a73e3etb5DupM=.56f6f88d42acefb82044cdb70827d26ee5ba86c2.incomplete'\n",
            "Downloading 'eval/truthfulqa/test.jsonl' to 'data_care/.cache/huggingface/download/eval/truthfulqa/3cj0bj5eu12ak_liUN7b-S5ObFs=.b4751b08a45a546ae9437a8badc0e4e3895fac08.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "test.jsonl: 4.94MB [00:00, 96.9MB/s]\n",
            "Download complete. Moving file to data_care/eval/triviaqa/test.jsonl\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "test.jsonl: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "test.jsonl: 672kB [00:00, 62.0MB/s]\n",
            "Download complete. Moving file to data_care/eval/truthfulqa/retrieval/colbertv2/test.jsonl\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "test_question_aware.jsonl: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "test_question_aware.jsonl: 740kB [00:00, 88.9MB/s]\n",
            "test.jsonl: 182kB [00:00, 114MB/s]\n",
            "Download complete. Moving file to data_care/eval/truthfulqa/retrieval/colbertv2/test_question_aware.jsonl\n",
            "Download complete. Moving file to data_care/eval/truthfulqa/test.jsonl\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "test.jsonl: 3.76MB [00:00, 16.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "test.jsonl: 6.31MB [00:00, 13.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'eval/webqa/retrieval/colbertv2/test.jsonl' to 'data_care/.cache/huggingface/download/eval/webqa/retrieval/colbertv2/3cj0bj5eu12ak_liUN7b-S5ObFs=.b5e31bdd74b18a323f70955ea23e81c521394d66.incomplete'\n",
            "Downloading 'eval/webqa/retrieval/colbertv2/test_question_aware.jsonl' to 'data_care/.cache/huggingface/download/eval/webqa/retrieval/colbertv2/bZSJqojxeCw2Z-a73e3etb5DupM=.91a4f07e4428ac83836bbabfaf6f5a451ab8d0f8.incomplete'\n",
            "Downloading 'finetune/nq_llama.jsonl' to 'data_care/.cache/huggingface/download/finetune/bCBgwQpSpCbe6e2jR-mV2nQpCaQ=.b2dafddeaceb697f86eb078b5e685c4945b55994acff8ab49baa0a69da142b35.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "test.jsonl: 9.90MB [00:00, 14.7MB/s]\n",
            "Download complete. Moving file to data_care/eval/triviaqa/retrieval/colbertv2/test.jsonl\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "test.jsonl: 1.57MB [00:00, 112MB/s]\n",
            "Download complete. Moving file to data_care/eval/webqa/retrieval/colbertv2/test.jsonl\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "test_question_aware.jsonl: 1.69MB [00:00, 123MB/s]\n",
            "Download complete. Moving file to data_care/eval/webqa/retrieval/colbertv2/test_question_aware.jsonl\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "finetune/nq_llama.jsonl:   0% 0.00/270M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'eval/webqa/test.jsonl' to 'data_care/.cache/huggingface/download/eval/webqa/3cj0bj5eu12ak_liUN7b-S5ObFs=.b09e6ba164cfbe1b5e8834b24d4759b9eca7e04e.incomplete'\n",
            "Downloading 'finetune/nq_mistral.jsonl' to 'data_care/.cache/huggingface/download/finetune/czjtG8mp0YnHivVsWnfFuiRbfCA=.e08f73464eb50517f09f8cc05633166d4b097cafe9b71cf79bce84f145395841.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "test.jsonl: 323kB [00:00, 124MB/s]\n",
            "Download complete. Moving file to data_care/eval/webqa/test.jsonl\n",
            "Downloading 'finetune/nq_qwen.jsonl' to 'data_care/.cache/huggingface/download/finetune/k0IbwjQelr1AJR8QKgQbesJe47o=.ad000101b75a62362fc497b059c1f837baa61ddf30508c937bb5a302c11e6568.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "finetune/nq_mistral.jsonl:   0% 0.00/277M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'finetune/nq_valid.jsonl' to 'data_care/.cache/huggingface/download/finetune/ZUP_bZB46Zo9Ob0rKseKeiKtyyg=.79f6b07988de128f282ef5e98986a17e7d08617f.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "finetune/nq_qwen.jsonl:   0% 0.00/265M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "nq_valid.jsonl: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'pretrain/dev.jsonl' to 'data_care/.cache/huggingface/download/pretrain/EuHUOb0iJ078zA8sVEvo8KskMBM=.b21d0edd4c3ee2719eeb83793325d483270757a6.incomplete'\n",
            "nq_valid.jsonl: 6.76MB [00:00, 115MB/s]\n",
            "Download complete. Moving file to data_care/finetune/nq_valid.jsonl\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "dev.jsonl: 1.26MB [00:00, 113MB/s]\n",
            "Download complete. Moving file to data_care/pretrain/dev.jsonl\n",
            "Downloading 'pretrain/train.jsonl' to 'data_care/.cache/huggingface/download/pretrain/uLTL3nZkD53R_81J3siCIpm58Y8=.0ad2fbcf1a173370e45fa4cfa9bd918f0476e579a60773551568d8b3bfeefaac.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pretrain/train.jsonl:   0% 0.00/1.26G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "eval/triviaqa/retrieval/colbertv2/test_q(‚Ä¶): 100% 11.1M/11.1M [00:03<00:00, 3.52MB/s]\n",
            "Download complete. Moving file to data_care/eval/triviaqa/retrieval/colbertv2/test_question_aware.jsonl\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "finetune/nq_llama.jsonl:   1% 2.31M/270M [00:02<05:05, 877kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "eval/triviaqa/train.jsonl: 100% 34.2M/34.2M [00:03<00:00, 9.01MB/s]\n",
            "Download complete. Moving file to data_care/eval/triviaqa/train.jsonl\n",
            "\n",
            "eval/nq/train.jsonl: 100% 12.4M/12.4M [00:04<00:00, 2.75MB/s]\n",
            "Download complete. Moving file to data_care/eval/nq/train.jsonl\n",
            "Fetching 24 files:  33% 8/24 [00:05<00:11,  1.44it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "finetune/nq_mistral.jsonl:   3% 8.32M/277M [00:03<01:37, 2.75MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pretrain/train.jsonl:   0% 557k/1.26G [00:02<1:40:22, 209kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "finetune/nq_llama.jsonl:  26% 69.3M/270M [00:04<00:10, 19.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "finetune/nq_llama.jsonl:  75% 203M/270M [00:04<00:00, 69.1MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "finetune/nq_llama.jsonl: 100% 270M/270M [00:04<00:00, 58.8MB/s]\n",
            "Download complete. Moving file to data_care/finetune/nq_llama.jsonl\n",
            "Fetching 24 files:  79% 19/24 [00:07<00:01,  3.04it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "finetune/nq_mistral.jsonl:  27% 75.3M/277M [00:04<00:09, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "finetune/nq_mistral.jsonl:  51% 142M/277M [00:04<00:02, 46.8MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "finetune/nq_mistral.jsonl:  76% 209M/277M [00:04<00:00, 78.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "finetune/nq_qwen.jsonl:  25% 67.0M/265M [00:04<00:13, 14.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "finetune/nq_qwen.jsonl:  51% 134M/265M [00:04<00:03, 34.5MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "finetune/nq_mistral.jsonl: 100% 277M/277M [00:04<00:00, 57.7MB/s]\n",
            "Download complete. Moving file to data_care/finetune/nq_mistral.jsonl\n",
            "Fetching 24 files:  83% 20/24 [00:07<00:01,  2.82it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "finetune/nq_qwen.jsonl:  75% 198M/265M [00:04<00:01, 59.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "finetune/nq_qwen.jsonl: 100% 265M/265M [00:04<00:00, 53.9MB/s]\n",
            "Download complete. Moving file to data_care/finetune/nq_qwen.jsonl\n",
            "Fetching 24 files:  88% 21/24 [00:10<00:01,  1.72it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pretrain/train.jsonl:   5% 67.6M/1.26G [00:06<01:39, 11.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pretrain/train.jsonl:  16% 202M/1.26G [00:06<00:24, 44.0MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pretrain/train.jsonl:  21% 269M/1.26G [00:06<00:15, 64.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pretrain/train.jsonl:  32% 403M/1.26G [00:06<00:07, 119MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pretrain/train.jsonl:  43% 537M/1.26G [00:07<00:03, 183MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pretrain/train.jsonl:  53% 671M/1.26G [00:07<00:02, 255MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pretrain/train.jsonl:  64% 805M/1.26G [00:07<00:01, 330MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pretrain/train.jsonl:  75% 940M/1.26G [00:07<00:00, 374MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pretrain/train.jsonl:  85% 1.07G/1.26G [00:07<00:00, 444MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pretrain/train.jsonl: 100% 1.26G/1.26G [00:08<00:00, 156MB/s]\n",
            "Download complete. Moving file to data_care/pretrain/train.jsonl\n",
            "Fetching 24 files: 100% 24/24 [00:12<00:00,  1.97it/s]\n",
            "/content/drive/MyDrive/CARE_L4_Full/CARE/data_care\n",
            "Êï∞ÊçÆÂáÜÂ§áÂÆåÊØï\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ÈÖçÁΩÆ L4 ‰ª£Á†Å (BF16 + Êó†FlashAttn)...\")\n",
        "\n",
        "# 1. ÂáÜÂ§á Demo Êï∞ÊçÆ\n",
        "!mkdir -p data_care/finetune\n",
        "!cp -f data_care/finetune/nq_mistral.jsonl data_care/finetune/nq_mistral.jsonl_demo\n",
        "!cp -f data_care/finetune/nq_valid.jsonl data_care/finetune/nq_valid.jsonl_demo\n",
        "\n",
        "# 2. [‰øÆÂ§ç] args.py ÂéüÁîü Bug\n",
        "!sed -i 's/if args.eval_file is not None:/if hasattr(args, \"eval_file\") and args.eval_file is not None:/g' src/utils/args.py\n",
        "\n",
        "# 3. [ÂÖ≥ÈîÆ] Âº∫Âà∂ÁßªÈô§‰ª£Á†Å‰∏≠ÁöÑ Flash Attention Ë∞ÉÁî®\n",
        "# Âéü‰ª£Á†ÅÈáåÂÜôÊ≠ª‰∫Ü use_flash_attention_2=TrueÔºåÂà†ÊéâÂÆÉËÆ© transformers Ëá™Âä®ÈÄâÊã©\n",
        "!sed -i '/use_flash_attention_2=/d' src/model/ICAE/modeling_icae.py\n",
        "\n",
        "# 4. [ÂÖ≥ÈîÆ] Ê≥®ÂÖ• 4-bit ÈáèÂåñ\n",
        "# ÈÖçÂêà BF16 ‰ΩøÁî®ÔºåÊó¢Á®≥ÂèàÂø´Ôºå‰∏îÊûÅÁúÅÊòæÂ≠ò\n",
        "!sed -i 's/config=config)/config=config, load_in_4bit=True)/g' src/model/ICAE/modeling_icae.py\n",
        "\n",
        "# 5. [ÂÖ≥ÈîÆ] ÈÖçÁΩÆÊñá‰ª∂Á¶ÅÁî® Flash Attention\n",
        "!sed -i 's/use_flash_attn: true/use_flash_attn: false/g' config/language_modeling/finetune.yaml\n",
        "\n",
        "print(\"ÈÖçÁΩÆÂÆåÊàêÔºöÂ∑≤ÂΩªÂ∫ïÂâ•Á¶ª Flash AttentionÔºåÂêØÁî® BF16 + 4-bit„ÄÇ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3xM5ETm1o57",
        "outputId": "ab3276a1-7a3d-4855-e9e7-f1e742c4446b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÈÖçÁΩÆ L4 ‰ª£Á†Å (BF16 + Êó†FlashAttn)...\n",
            "ÈÖçÁΩÆÂÆåÊàêÔºöÂ∑≤ÂΩªÂ∫ïÂâ•Á¶ª Flash AttentionÔºåÂêØÁî® BF16 + 4-bit„ÄÇ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üßπ Ê≠£Âú®‰øÆÂ§çÁº©ËøõÈîôËØØ...\")\n",
        "\n",
        "# 1. ‰ªÖÈáçÁΩÆ train.py (‰øùÁïôÂÖ∂‰ªñÊñá‰ª∂ÁöÑ‰øÆÊîπ)\n",
        "!git checkout src/language_modeling/train.py\n",
        "\n",
        "# 2. [Ë°•‰∏Å1] ÂÜçÊ¨°Â∫îÁî® strict=False (Âä†ËΩΩÊùÉÈáçÂøÖÈ°ª)\n",
        "!sed -i 's/model.load_state_dict(model_state_dict)/model.load_state_dict(model_state_dict, strict=False)/g' src/language_modeling/train.py\n",
        "\n",
        "# 3. [Ë°•‰∏Å2] ÂÆåÁæéÊõøÊç¢È™åËØÅ‰ª£Á†Å (‰øùÊåÅÁº©Ëøõ)\n",
        "# ‰ΩøÁî®Ê≠£ÂàôË°®ËææÂºèÊõøÊç¢Êï¥Ë°åË∞ÉÁî®ÔºåÂ∞ÜÂÖ∂Âèò‰∏∫ score = 0.0\n",
        "# Âõ†‰∏∫Ê≤°ÊúâÂåπÈÖçË°åÈ¶ñÁöÑÁ©∫Ê†ºÔºåsed ‰ºö‰øùÁïôÂéüÊúâÁöÑÁº©ËøõÔºåËøôËß£ÂÜ≥‰∫Ü IndentationError\n",
        "!sed -i 's/score = validate_during_finetune(.*)/score = 0.0/g' src/language_modeling/train.py\n",
        "\n",
        "print(\"‚úÖ train.py Â∑≤‰øÆÂ§çÔºöValidation Ë¢´ÂÆâÂÖ®Ë∑≥ËøáÔºåÁº©ËøõÊ≠£Â∏∏„ÄÇ\")\n",
        "print(\"----------------------------------------------------------------\")\n",
        "print(\"üöÄ 10. ÂêØÂä® Demo (ËßÅËØÅÂ•áËøπÊó∂Âàª)...\")\n",
        "\n",
        "# ÂêØÂä®ÂëΩ‰ª§\n",
        "!export WANDB_MODE=offline && accelerate launch \\\n",
        "    --mixed_precision bf16 \\\n",
        "    --num_processes 1 \\\n",
        "    -m src.language_modeling.train \\\n",
        "    --config config/language_modeling/finetune.yaml \\\n",
        "    --dev_file data_care/finetune/nq_valid.jsonl \\\n",
        "    --train_file data_care/finetune/nq_mistral.jsonl \\\n",
        "    --model_name_or_path mistralai/mistral-7b-instruct-v0.2 \\\n",
        "    --checkpoint_path checkpoints/care_mistral_pt \\\n",
        "    --learning_rate 1e-4 \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --max_train_steps 20 \\\n",
        "    --per_device_train_batch_size 1 \\\n",
        "    --gradient_accumulation_steps 32 \\\n",
        "    --alpha_kl 2 \\\n",
        "    --exp_name care_mistral_demo_L4 \\\n",
        "    --demo True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1BycQDt4BKI",
        "outputId": "5150444b-eb6a-4de0-9428-23ae01a894c1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üßπ Ê≠£Âú®‰øÆÂ§çÁº©ËøõÈîôËØØ...\n",
            "Updated 1 path from the index\n",
            "‚úÖ train.py Â∑≤‰øÆÂ§çÔºöValidation Ë¢´ÂÆâÂÖ®Ë∑≥ËøáÔºåÁº©ËøõÊ≠£Â∏∏„ÄÇ\n",
            "----------------------------------------------------------------\n",
            "üöÄ 10. ÂêØÂä® Demo (ËßÅËØÅÂ•áËøπÊó∂Âàª)...\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2026-01-01 07:31:34.275244: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-01 07:31:34.293225: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767252694.314792   69394 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767252694.321347   69394 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767252694.338164   69394 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767252694.338196   69394 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767252694.338199   69394 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767252694.338202   69394 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-01 07:31:34.343055: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "{'model_name_or_path', 'gradient_accumulation_steps', 'demo', 'alpha_kl', 'config', 'max_train_steps', 'num_train_epochs', 'per_device_train_batch_size', 'exp_name', 'train_file', 'checkpoint_path', 'learning_rate', 'dev_file'}\n",
            "> [ES] CLI argument is given for train_file, so ignore the YAML config.\n",
            "****************************************************************************************************\n",
            "**************************************************\n",
            "\n",
            "\n",
            "> [ES] Running the demo mode.\n",
            "\n",
            "\n",
            "**************************************************\n",
            "****************************************************************************************************\n",
            "> chat_format is ICAE, ICAE Memory Size: 16\n",
            "> Mem size: 16, Mem Hidden Size: 4096\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./wandb/offline-run-20260101_073140-v8yugtih\u001b[0m\n",
            "{\n",
            "    \"use_fast_tokenizer\": null,\n",
            "    \"use_rag_tuning\": true,\n",
            "    \"chat_format\": \"icae\",\n",
            "    \"max_train_samples\": null,\n",
            "    \"update_projector_only\": true,\n",
            "    \"workdir\": \".\",\n",
            "    \"config\": \"config/language_modeling/finetune.yaml\",\n",
            "    \"task_type\": \"finetune\",\n",
            "    \"retrieval_context_length\": 180,\n",
            "    \"alpha_nll\": 1.0,\n",
            "    \"alpha_kl\": 2.0,\n",
            "    \"kl_temperature\": 1.0,\n",
            "    \"train_file\": \"data_care/finetune/nq_mistral.jsonl_demo\",\n",
            "    \"dev_file\": \"data_care/finetune/nq_valid.jsonl_demo\",\n",
            "    \"model_name_or_path\": \"mistralai/mistral-7b-instruct-v0.2\",\n",
            "    \"use_flash_attn\": false,\n",
            "    \"max_seq_length\": 1024,\n",
            "    \"per_device_train_batch_size\": 1,\n",
            "    \"learning_rate\": 0.0001,\n",
            "    \"weight_decay\": 0.0,\n",
            "    \"num_train_epochs\": 1,\n",
            "    \"max_train_steps\": 20,\n",
            "    \"gradient_accumulation_steps\": 32,\n",
            "    \"lr_scheduler_type\": \"linear\",\n",
            "    \"warmup_ratio\": 0.03,\n",
            "    \"project_name\": \"care\",\n",
            "    \"exp_name\": \"care_mistral_demo_L4\",\n",
            "    \"exp_note\": null,\n",
            "    \"seed\": 980406,\n",
            "    \"preprocessing_num_workers\": 1,\n",
            "    \"overwrite_cache\": false,\n",
            "    \"checkpointing_steps\": 1,\n",
            "    \"logging_steps\": 1,\n",
            "    \"clip_grad_norm\": -1.0,\n",
            "    \"ret_embedding_path\": null,\n",
            "    \"checkpoint_path\": \"checkpoints/care_mistral_pt\",\n",
            "    \"demo\": true,\n",
            "    \"icae_mem_size\": 16,\n",
            "    \"ctx_nll\": \"gt\",\n",
            "    \"ctx_student\": \"gt\",\n",
            "    \"ctx_teacher\": \"adaptive\",\n",
            "    \"ctx_nll_gt_prob\": 0.0,\n",
            "    \"ctx_student_gt_prob\": 0.0,\n",
            "    \"ctx_teacher_gt_prob\": 0.0,\n",
            "    \"select_criteria\": \"closed_book_correct\",\n",
            "    \"ctx_select\": \"hn\",\n",
            "    \"same_nll_kl\": true\n",
            "}\n",
            "> output_dir: ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint\n",
            "loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--mistralai--mistral-7b-instruct-v0.2/snapshots/63a8b081895390a26e140280378bc85ec8bce07a/tokenizer.model\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--mistralai--mistral-7b-instruct-v0.2/snapshots/63a8b081895390a26e140280378bc85ec8bce07a/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--mistralai--mistral-7b-instruct-v0.2/snapshots/63a8b081895390a26e140280378bc85ec8bce07a/tokenizer_config.json\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--mistralai--mistral-7b-instruct-v0.2/snapshots/63a8b081895390a26e140280378bc85ec8bce07a/tokenizer.json\n",
            "loading file chat_template.jinja from cache at None\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mistralai--mistral-7b-instruct-v0.2/snapshots/63a8b081895390a26e140280378bc85ec8bce07a/config.json\n",
            "Model config MistralICAEConfig {\n",
            "  \"architectures\": [\n",
            "    \"MistralForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"mem_hidden_size\": 4096,\n",
            "  \"mem_size\": 16,\n",
            "  \"model_type\": \"mistral\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"projector_type\": \"mlp2x_gelu\",\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "The device_map was not initialized. Setting device_map to {'': 0}. If you want to use the model for inference, please set device_map ='auto' \n",
            "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--mistralai--mistral-7b-instruct-v0.2/snapshots/63a8b081895390a26e140280378bc85ec8bce07a/model.safetensors.index.json\n",
            "Instantiating MistralForCausalLM model under default dtype torch.bfloat16.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2\n",
            "}\n",
            "\n",
            "Loading checkpoint shards: 100% 3/3 [00:16<00:00,  5.57s/it]\n",
            "All model checkpoint weights were used when initializing MistralForCausalLM.\n",
            "\n",
            "All the weights of MistralForCausalLM were initialized from the model checkpoint at mistralai/mistral-7b-instruct-v0.2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.\n",
            "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--mistralai--mistral-7b-instruct-v0.2/snapshots/63a8b081895390a26e140280378bc85ec8bce07a/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2\n",
            "}\n",
            "\n",
            "trainable params: 251731968 || all params: 4003803136 || trainable%: 6.287321315490373\n",
            "loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--mistralai--mistral-7b-instruct-v0.2/snapshots/63a8b081895390a26e140280378bc85ec8bce07a/tokenizer.model\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--mistralai--mistral-7b-instruct-v0.2/snapshots/63a8b081895390a26e140280378bc85ec8bce07a/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--mistralai--mistral-7b-instruct-v0.2/snapshots/63a8b081895390a26e140280378bc85ec8bce07a/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--mistralai--mistral-7b-instruct-v0.2/snapshots/63a8b081895390a26e140280378bc85ec8bce07a/tokenizer_config.json\n",
            "loading file chat_template.jinja from cache at None\n",
            "> Save the model code to the output directory, /content/drive/MyDrive/CARE_L4_Full/CARE/src/model/ICAE/modeling_icae.py\n",
            "Resizing token embeddings from 32000 to 32002\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32002. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "> loading checkpoint from checkpoints/care_mistral_pt\n",
            "> select_criteria is not None, closed_book_correct\n",
            "> Convert the background to hn_background if the closed_book_correct is satisfied\n",
            "  0% 0/20 [00:00<?, ?it/s]**************************************** show one example ****************************************\n",
            "dict_keys(['ids', 'answers', 'random_background_ids', 'hn_background_ids', 'xrag_input_ids', 'xrag_attention_mask', 'xrag_labels', 'hn_xrag_input_ids', 'hn_xrag_attention_mask', 'hn_xrag_labels', 'gt_xrag_input_ids', 'gt_xrag_attention_mask', 'gt_xrag_labels', 'retriever_input_ids', 'retriever_attention_mask', 'hn_retriever_input_ids', 'hn_retriever_attention_mask', 'gt_retriever_input_ids', 'gt_retriever_attention_mask', 'input_ids', 'attention_mask', 'labels', 'random_input_ids', 'random_attention_mask', 'random_labels', 'hn_input_ids', 'hn_attention_mask', 'hn_labels', 'gt_input_ids', 'gt_attention_mask', 'gt_labels', 'none_input_ids', 'none_attention_mask', 'none_labels', 'adaptive_input_ids', 'adaptive_attention_mask', 'adaptive_labels'])\n",
            "<s>[INST] Refer to the background document:  <xRAG> <xRAG> <xRAG> <xRAG> <xRAG> <xRAG> <xRAG> <xRAG> <xRAG> <xRAG> <xRAG> <xRAG> <xRAG> <xRAG> <xRAG> <xRAG> \n",
            "\n",
            "Can you tell me the answer to where does the name iron maiden come from? [/INST]iron maiden torture device</s>\n",
            "tensor([    1, 28792, 16289, 28793, 25958,   298,   272,  5414,  3248, 28747,\n",
            "        28705, 32001, 32001, 32001, 32001, 32001, 32001, 32001, 32001, 32001,\n",
            "        32001, 32001, 32001, 32001, 32001, 32001, 32001,    13,    13,  6325,\n",
            "          368,  1912,   528,   272,  4372,   298,   970,  1235,   272,  1141,\n",
            "         8075, 23408,   269,  1567,   477, 28804,   733, 28748, 16289, 28793,\n",
            "         2311, 23408,   269, 26026,  3895,     2], device='cuda:0')\n",
            "<s>(-100)(1) [(-100)(1) INST(-100)(1) ](-100)(1) ‚ñÅRefer(-100)(1) ‚ñÅto(-100)(1) ‚ñÅthe(-100)(1) ‚ñÅbackground(-100)(1) ‚ñÅdocument(-100)(1) :(-100)(1) ‚ñÅQuestion(-100)(1) :(-100)(1) ‚ñÅwhere(-100)(1) ‚ñÅdoes(-100)(1) ‚ñÅthe(-100)(1) ‚ñÅname(-100)(1) ‚ñÅiron(-100)(1) ‚ñÅmaid(-100)(1) en(-100)(1) ‚ñÅcome(-100)(1) ‚ñÅfrom(-100)(1) <0x0A>(-100)(1) Document(-100)(1) :(-100)(1) ‚ñÅDocument(-100)(1) :(-100)(1) ‚ñÅIron(-100)(1) ‚ñÅM(-100)(1) aid(-100)(1) en(-100)(1) ‚ñÅ|(-100)(1) ‚ñÅ‚ñÅ(-100)(1) ‚ñÅIron(-100)(1) ‚ñÅM(-100)(1) aid(-100)(1) en(-100)(1) ‚ñÅwere(-100)(1) ‚ñÅformed(-100)(1) ‚ñÅon(-100)(1) ‚ñÅChristmas(-100)(1) ‚ñÅDay(-100)(1) ,(-100)(1) ‚ñÅ(-100)(1) 2(-100)(1) 5(-100)(1) ‚ñÅDecember(-100)(1) ‚ñÅ(-100)(1) 1(-100)(1) 9(-100)(1) 7(-100)(1) 5(-100)(1) ‚ñÅby(-100)(1) ‚ñÅbass(-100)(1) ist(-100)(1) ‚ñÅSteve(-100)(1) ‚ñÅHarris(-100)(1) ‚ñÅshortly(-100)(1) ‚ñÅafter(-100)(1) ‚ñÅhe(-100)(1) ‚ñÅleft(-100)(1) ‚ñÅhis(-100)(1) ‚ñÅprevious(-100)(1) ‚ñÅgroup(-100)(1) ,(-100)(1) ‚ñÅSm(-100)(1) iler(-100)(1) .(-100)(1) ‚ñÅHarris(-100)(1) ‚ñÅattributed(-100)(1) ‚ñÅthe(-100)(1) ‚ñÅband(-100)(1) '(-100)(1) s(-100)(1) ‚ñÅname(-100)(1) ‚ñÅto(-100)(1) ‚ñÅa(-100)(1) ‚ñÅfilm(-100)(1) ‚ñÅadaptation(-100)(1) ‚ñÅof(-100)(1) ‚ñÅThe(-100)(1) ‚ñÅMan(-100)(1) ‚ñÅin(-100)(1) ‚ñÅthe(-100)(1) ‚ñÅIron(-100)(1) ‚ñÅMask(-100)(1) ‚ñÅfrom(-100)(1) ‚ñÅthe(-100)(1) ‚ñÅnovel(-100)(1) ‚ñÅby(-100)(1) ‚ñÅAlexand(-100)(1) re(-100)(1) ‚ñÅDum(-100)(1) as(-100)(1) ,(-100)(1) ‚ñÅthe(-100)(1) ‚ñÅtitle(-100)(1) ‚ñÅof(-100)(1) ‚ñÅwhich(-100)(1) ‚ñÅreminded(-100)(1) ‚ñÅhim(-100)(1) ‚ñÅof(-100)(1) ‚ñÅthe(-100)(1) ‚ñÅiron(-100)(1) ‚ñÅmaid(-100)(1) en(-100)(1) ‚ñÅtorture(-100)(1) ‚ñÅdevice(-100)(1) .(-100)(1) ‚ñÅAfter(-100)(1) ‚ñÅmonths(-100)(1) ‚ñÅof(-100)(1) ‚ñÅrehe(-100)(1) ars(-100)(1) al(-100)(1) ,(-100)(1) ‚ñÅIron(-100)(1) ‚ñÅM(-100)(1) aid(-100)(1) en(-100)(1) ‚ñÅmade(-100)(1) ‚ñÅtheir(-100)(1) ‚ñÅdebut(-100)(1) ‚ñÅat(-100)(1) ‚ñÅSt(-100)(1) .(-100)(1) ‚ñÅN(-100)(1) icks(-100)(1) ‚ñÅHall(-100)(1) ‚ñÅin(-100)(1) ‚ñÅPop(-100)(1) lar(-100)(1) ‚ñÅon(-100)(1) ‚ñÅ(-100)(1) 1(-100)(1) ‚ñÅMay(-100)(1) ‚ñÅ(-100)(1) 1(-100)(1) 9(-100)(1) 7(-100)(1) 6(-100)(1) ,(-100)(1) ‚ñÅbefore(-100)(1) ‚ñÅtaking(-100)(1) ‚ñÅup(-100)(1) ‚ñÅa(-100)(1) ‚ñÅsemi(-100)(1) -(-100)(1) res(-100)(1) id(-100)(1) ency(-100)(1) ‚ñÅat(-100)(1) ‚ñÅthe(-100)(1) ‚ñÅCart(-100)(1) ‚ñÅand(-100)(1) ‚ñÅH(-100)(1) ors(-100)(1) es(-100)(1) ‚ñÅPub(-100)(1) ‚ñÅin(-100)(1) ‚ñÅMaryland(-100)(1) ,(-100)(1) ‚ñÅStr(-100)(1) at(-100)(1) ford(-100)(1) .(-100)(1) ‚ñÅA(-100)(1) ‚ñÅfew(-100)(1) ‚ñÅdecades(-100)(1) ‚ñÅlater(-100)(1) ‚ñÅthe(-100)(1) ‚ñÅpub(-100)(1) ‚ñÅin(-100)(1) ‚ñÅMaryland(-100)(1) ‚ñÅwas(-100)(1) ‚ñÅofficially(-100)(1) ‚ñÅnamed(-100)(1) ‚ñÅ\"(-100)(1) The(-100)(1) ‚ñÅBirth(-100)(1) place(-100)(1) ‚ñÅof(-100)(1) ‚ñÅIron(-100)(1) ‚ñÅ(-100)(1) <0x0A>(-100)(1) Question(-100)(1) :(-100)(1) ‚ñÅwhere(-100)(1) ‚ñÅdoes(-100)(1) ‚ñÅthe(-100)(1) ‚ñÅname(-100)(1) ‚ñÅiron(-100)(1) ‚ñÅmaid(-100)(1) en(-100)(1) ‚ñÅcome(-100)(1) ‚ñÅfrom(-100)(1) <0x0A>(-100)(1) <0x0A>(-100)(1) Can(-100)(1) ‚ñÅyou(-100)(1) ‚ñÅtell(-100)(1) ‚ñÅme(-100)(1) ‚ñÅthe(-100)(1) ‚ñÅanswer(-100)(1) ‚ñÅto(-100)(1) ‚ñÅwhere(-100)(1) ‚ñÅdoes(-100)(1) ‚ñÅthe(-100)(1) ‚ñÅname(-100)(1) ‚ñÅiron(-100)(1) ‚ñÅmaid(-100)(1) en(-100)(1) ‚ñÅcome(-100)(1) ‚ñÅfrom(-100)(1) ?(-100)(1) ‚ñÅ[(-100)(1) /(-100)(1) INST(-100)(1) ](-100)(1) iron(2311)(1) ‚ñÅmaid(23408)(1) en(269)(1) ‚ñÅtorture(26026)(1) ‚ñÅdevice(3895)(1) </s>(2)(1) \n",
            "<s>(-100)(1) [(-100)(1) INST(-100)(1) ](-100)(1) ‚ñÅRefer(-100)(1) ‚ñÅto(-100)(1) ‚ñÅthe(-100)(1) ‚ñÅbackground(-100)(1) ‚ñÅdocument(-100)(1) :(-100)(1) ‚ñÅ(-100)(1) <xRAG>(-100)(1) <xRAG>(-100)(1) <xRAG>(-100)(1) <xRAG>(-100)(1) <xRAG>(-100)(1) <xRAG>(-100)(1) <xRAG>(-100)(1) <xRAG>(-100)(1) <xRAG>(-100)(1) <xRAG>(-100)(1) <xRAG>(-100)(1) <xRAG>(-100)(1) <xRAG>(-100)(1) <xRAG>(-100)(1) <xRAG>(-100)(1) <xRAG>(-100)(1) <0x0A>(-100)(1) <0x0A>(-100)(1) Can(-100)(1) ‚ñÅyou(-100)(1) ‚ñÅtell(-100)(1) ‚ñÅme(-100)(1) ‚ñÅthe(-100)(1) ‚ñÅanswer(-100)(1) ‚ñÅto(-100)(1) ‚ñÅwhere(-100)(1) ‚ñÅdoes(-100)(1) ‚ñÅthe(-100)(1) ‚ñÅname(-100)(1) ‚ñÅiron(-100)(1) ‚ñÅmaid(-100)(1) en(-100)(1) ‚ñÅcome(-100)(1) ‚ñÅfrom(-100)(1) ?(-100)(1) ‚ñÅ[(-100)(1) /(-100)(1) INST(-100)(1) ](-100)(1) iron(2311)(1) ‚ñÅmaid(23408)(1) en(269)(1) ‚ñÅtorture(26026)(1) ‚ñÅdevice(3895)(1) </s>(2)(1) \n",
            "**************************************** show one example ****************************************\n",
            "`torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to eager attention. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
            "  5% 1/20 [01:29<28:12, 89.06s/it]Configuration saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_1/config.json\n",
            "tokenizer config file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_1/tokenizer_config.json\n",
            "Special tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_1/special_tokens_map.json\n",
            "added tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_1/added_tokens.json\n",
            "> 1 steps, EM score: 0.0\n",
            " 10% 2/20 [03:04<27:51, 92.88s/it]Configuration saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_2/config.json\n",
            "tokenizer config file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_2/tokenizer_config.json\n",
            "Special tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_2/special_tokens_map.json\n",
            "added tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_2/added_tokens.json\n",
            "> 2 steps, EM score: 0.0\n",
            " 15% 3/20 [04:34<25:52, 91.30s/it]Configuration saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_3/config.json\n",
            "tokenizer config file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_3/tokenizer_config.json\n",
            "Special tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_3/special_tokens_map.json\n",
            "added tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_3/added_tokens.json\n",
            "> 3 steps, EM score: 0.0\n",
            " 20% 4/20 [06:10<24:50, 93.16s/it]Configuration saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_4/config.json\n",
            "tokenizer config file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_4/tokenizer_config.json\n",
            "Special tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_4/special_tokens_map.json\n",
            "added tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_4/added_tokens.json\n",
            "> 4 steps, EM score: 0.0\n",
            " 25% 5/20 [07:42<23:14, 92.94s/it]Configuration saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_5/config.json\n",
            "tokenizer config file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_5/tokenizer_config.json\n",
            "Special tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_5/special_tokens_map.json\n",
            "added tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_5/added_tokens.json\n",
            "> 5 steps, EM score: 0.0\n",
            " 30% 6/20 [09:16<21:44, 93.17s/it]Configuration saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_6/config.json\n",
            "tokenizer config file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_6/tokenizer_config.json\n",
            "Special tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_6/special_tokens_map.json\n",
            "added tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_6/added_tokens.json\n",
            "> 6 steps, EM score: 0.0\n",
            " 35% 7/20 [10:46<19:57, 92.14s/it]Configuration saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_7/config.json\n",
            "tokenizer config file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_7/tokenizer_config.json\n",
            "Special tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_7/special_tokens_map.json\n",
            "added tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_7/added_tokens.json\n",
            "> 7 steps, EM score: 0.0\n",
            " 40% 8/20 [12:18<18:27, 92.25s/it]Configuration saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_8/config.json\n",
            "tokenizer config file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_8/tokenizer_config.json\n",
            "Special tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_8/special_tokens_map.json\n",
            "added tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_8/added_tokens.json\n",
            "> 8 steps, EM score: 0.0\n",
            " 45% 9/20 [13:51<16:57, 92.46s/it]Configuration saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_9/config.json\n",
            "tokenizer config file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_9/tokenizer_config.json\n",
            "Special tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_9/special_tokens_map.json\n",
            "added tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_9/added_tokens.json\n",
            "> 9 steps, EM score: 0.0\n",
            " 50% 10/20 [15:16<15:01, 90.19s/it]Configuration saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_10/config.json\n",
            "tokenizer config file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_10/tokenizer_config.json\n",
            "Special tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_10/special_tokens_map.json\n",
            "added tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_10/added_tokens.json\n",
            "> 10 steps, EM score: 0.0\n",
            " 55% 11/20 [16:49<13:39, 91.02s/it]Configuration saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_11/config.json\n",
            "tokenizer config file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_11/tokenizer_config.json\n",
            "Special tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_11/special_tokens_map.json\n",
            "added tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_11/added_tokens.json\n",
            "> 11 steps, EM score: 0.0\n",
            " 60% 12/20 [18:20<12:07, 90.90s/it]Configuration saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_12/config.json\n",
            "tokenizer config file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_12/tokenizer_config.json\n",
            "Special tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_12/special_tokens_map.json\n",
            "added tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_12/added_tokens.json\n",
            "> 12 steps, EM score: 0.0\n",
            " 65% 13/20 [19:51<10:36, 90.94s/it]Configuration saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_13/config.json\n",
            "tokenizer config file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_13/tokenizer_config.json\n",
            "Special tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_13/special_tokens_map.json\n",
            "added tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_13/added_tokens.json\n",
            "> 13 steps, EM score: 0.0\n",
            " 70% 14/20 [21:23<09:07, 91.18s/it]Configuration saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_14/config.json\n",
            "tokenizer config file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_14/tokenizer_config.json\n",
            "Special tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_14/special_tokens_map.json\n",
            "added tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_14/added_tokens.json\n",
            "> 14 steps, EM score: 0.0\n",
            " 75% 15/20 [22:53<07:34, 90.87s/it]Configuration saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_15/config.json\n",
            "tokenizer config file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_15/tokenizer_config.json\n",
            "Special tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_15/special_tokens_map.json\n",
            "added tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_15/added_tokens.json\n",
            "> 15 steps, EM score: 0.0\n",
            " 80% 16/20 [24:27<06:07, 91.98s/it]Configuration saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_16/config.json\n",
            "tokenizer config file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_16/tokenizer_config.json\n",
            "Special tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_16/special_tokens_map.json\n",
            "added tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_16/added_tokens.json\n",
            "> 16 steps, EM score: 0.0\n",
            " 85% 17/20 [26:04<04:40, 93.46s/it]Configuration saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_17/config.json\n",
            "tokenizer config file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_17/tokenizer_config.json\n",
            "Special tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_17/special_tokens_map.json\n",
            "added tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_17/added_tokens.json\n",
            "> 17 steps, EM score: 0.0\n",
            " 90% 18/20 [27:33<03:04, 92.15s/it]Configuration saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_18/config.json\n",
            "tokenizer config file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_18/tokenizer_config.json\n",
            "Special tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_18/special_tokens_map.json\n",
            "added tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_18/added_tokens.json\n",
            "> 18 steps, EM score: 0.0\n",
            " 95% 19/20 [29:08<01:32, 92.96s/it]Configuration saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_19/config.json\n",
            "tokenizer config file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_19/tokenizer_config.json\n",
            "Special tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_19/special_tokens_map.json\n",
            "added tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_19/added_tokens.json\n",
            "> 19 steps, EM score: 0.0\n",
            "100% 20/20 [30:38<00:00, 91.91s/it]Configuration saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_20/config.json\n",
            "tokenizer config file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_20/tokenizer_config.json\n",
            "Special tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_20/special_tokens_map.json\n",
            "added tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/step_20/added_tokens.json\n",
            "> 20 steps, EM score: 0.0\n",
            "> 20 steps, EM score: 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          Span-EM ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    learning_rate ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  rolling_kl_loss ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     rolling_loss ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: rolling_nll_loss ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train_loss ‚ñà‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          Span-EM 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    learning_rate 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  rolling_kl_loss 1.79662\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     rolling_loss 6.045\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: rolling_nll_loss 2.45177\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train_loss 5.0518\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync ./wandb/offline-run-20260101_073140-v8yugtih\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20260101_073140-v8yugtih/logs\u001b[0m\n",
            "Configuration saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/last/config.json\n",
            "tokenizer config file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/last/tokenizer_config.json\n",
            "Special tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/last/special_tokens_map.json\n",
            "added tokens file saved in ./wandb/offline-run-20260101_073140-v8yugtih/files/checkpoint/last/added_tokens.json\n",
            "> Successfully renamed ./wandb/offline-run-20260101_073140-v8yugtih to wandb/care_mistral_demo_L4\n",
            "100% 20/20 [30:44<00:00, 92.21s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SJsUiUAn4loA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}